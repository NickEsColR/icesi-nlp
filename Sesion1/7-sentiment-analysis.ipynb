{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de Sentimientos en tweets sobre vacunas del Covid-19\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NickEsColR/icesi-nlp/blob/main/Sesion1/7-sentiment-analysis.ipynb)\n",
    "\n",
    "Ahora pongamos en práctica algunos de estos conceptos en un caso más real. Para esta práctica vamos a hacer un análisis de sentimientos sobre unos tweets de vacunas del Covid-19. Este caso sería una simple clasificación binaria y podemos utilizar cualquier modelo para ese fin, lo adicional aquí es el pre-procesamiento de las entradas de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset de Kaggle [Covid-19 Vaccine Tweets with Sentiment Annotation](https://www.kaggle.com/datasets/datasciencetool/covid19-vaccine-tweets-with-sentiment-annotation?resource=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18240/2396000874.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "installed_packages = [package.key for package in pkg_resources.working_set]\n",
    "IN_COLAB = 'google-colab' in installed_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test '{IN_COLAB}' = 'True' && wget  https://github.com/Ohtar10/icesi-nlp/raw/refs/heads/main/requirements.txt && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test '{IN_COLAB}' = 'True' && wget  https://github.com/NickEsColR/icesi-nlp/raw/refs/heads/main/Sesion1/covid-19_vaccine_tweets_with_sentiment.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empecemos por cargar el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.360342e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>4,000 a day dying from the so called Covid-19 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.382896e+18</td>\n",
       "      <td>2</td>\n",
       "      <td>Pranam message for today manifested in Dhyan b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.375673e+18</td>\n",
       "      <td>2</td>\n",
       "      <td>Hyderabad-based ?@BharatBiotech? has sought fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.381311e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>Confirmation that Chinese #vaccines \"dont hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.362166e+18</td>\n",
       "      <td>3</td>\n",
       "      <td>Lab studies suggest #Pfizer, #Moderna vaccines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id  label                                         tweet_text\n",
       "0  1.360342e+18      1  4,000 a day dying from the so called Covid-19 ...\n",
       "1  1.382896e+18      2  Pranam message for today manifested in Dhyan b...\n",
       "2  1.375673e+18      2  Hyderabad-based ?@BharatBiotech? has sought fu...\n",
       "3  1.381311e+18      1  Confirmation that Chinese #vaccines \"dont hav...\n",
       "4  1.362166e+18      3  Lab studies suggest #Pfizer, #Moderna vaccines..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets = pd.read_csv('./covid-19_vaccine_tweets_with_sentiment.csv', sep=',', encoding='latin1') # type: ignore\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, hagamos algo de limpieza, vamos a remover nulos y valores vacíos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.dropna(inplace=True)\n",
    "tweets.tweet_text = tweets.tweet_text.apply(lambda r: r.strip())\n",
    "blanks = tweets[tweets.tweet_text == ''].index\n",
    "tweets.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets.tweet_text == ''].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que no queda ningún tweet vació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    3680\n",
       "3    1900\n",
       "1     420\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un dataset desbalanceado de 1900 ejemplares positivos y 420 negativos. (el 2 es neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.360342e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>4,000 a day dying from the so called Covid-19 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.381311e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>Confirmation that Chinese #vaccines \"dont hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.362166e+18</td>\n",
       "      <td>3</td>\n",
       "      <td>Lab studies suggest #Pfizer, #Moderna vaccines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.351285e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>Still want to take the #jab?\\n#PfizerBioNTech\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.363344e+18</td>\n",
       "      <td>3</td>\n",
       "      <td>#Covaxin effective against mutant virus strain...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id  label                                         tweet_text\n",
       "0  1.360342e+18      1  4,000 a day dying from the so called Covid-19 ...\n",
       "1  1.381311e+18      1  Confirmation that Chinese #vaccines \"dont hav...\n",
       "2  1.362166e+18      3  Lab studies suggest #Pfizer, #Moderna vaccines...\n",
       "3  1.351285e+18      1  Still want to take the #jab?\\n#PfizerBioNTech\\...\n",
       "4  1.363344e+18      3  #Covaxin effective against mutant virus strain..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets[tweets.label != 2]\n",
    "tweets.reset_index(drop=True, inplace=True)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer las cosas simples, vamos a utilizar un VADER para computar el puntaje de positivo o negativo. Este modelo ya viene implementado dentro de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.360342e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>4,000 a day dying from the so called Covid-19 ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.381311e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>Confirmation that Chinese #vaccines \"dont hav...</td>\n",
       "      <td>{'neg': 0.148, 'neu': 0.852, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.362166e+18</td>\n",
       "      <td>3</td>\n",
       "      <td>Lab studies suggest #Pfizer, #Moderna vaccines...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.794, 'pos': 0.206, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.351285e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>Still want to take the #jab?\\n#PfizerBioNTech\\...</td>\n",
       "      <td>{'neg': 0.198, 'neu': 0.759, 'pos': 0.043, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.363344e+18</td>\n",
       "      <td>3</td>\n",
       "      <td>#Covaxin effective against mutant virus strain...</td>\n",
       "      <td>{'neg': 0.116, 'neu': 0.657, 'pos': 0.228, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id  label                                         tweet_text  \\\n",
       "0  1.360342e+18      1  4,000 a day dying from the so called Covid-19 ...   \n",
       "1  1.381311e+18      1  Confirmation that Chinese #vaccines \"dont hav...   \n",
       "2  1.362166e+18      3  Lab studies suggest #Pfizer, #Moderna vaccines...   \n",
       "3  1.351285e+18      1  Still want to take the #jab?\\n#PfizerBioNTech\\...   \n",
       "4  1.363344e+18      3  #Covaxin effective against mutant virus strain...   \n",
       "\n",
       "                                              scores  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1  {'neg': 0.148, 'neu': 0.852, 'pos': 0.0, 'comp...  \n",
       "2  {'neg': 0.0, 'neu': 0.794, 'pos': 0.206, 'comp...  \n",
       "3  {'neg': 0.198, 'neu': 0.759, 'pos': 0.043, 'co...  \n",
       "4  {'neg': 0.116, 'neu': 0.657, 'pos': 0.228, 'co...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "tweets['scores'] = tweets.tweet_text.apply(lambda r: sid.polarity_scores(r))\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos puntajes ahora podemos convertir el resultado en una etiqueta de predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.360342e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>4,000 a day dying from the so called Covid-19 ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.381311e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>Confirmation that Chinese #vaccines \"dont hav...</td>\n",
       "      <td>{'neg': 0.148, 'neu': 0.852, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.7783</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.362166e+18</td>\n",
       "      <td>3</td>\n",
       "      <td>Lab studies suggest #Pfizer, #Moderna vaccines...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.794, 'pos': 0.206, 'comp...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.351285e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>Still want to take the #jab?\\n#PfizerBioNTech\\...</td>\n",
       "      <td>{'neg': 0.198, 'neu': 0.759, 'pos': 0.043, 'co...</td>\n",
       "      <td>-0.6908</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.363344e+18</td>\n",
       "      <td>3</td>\n",
       "      <td>#Covaxin effective against mutant virus strain...</td>\n",
       "      <td>{'neg': 0.116, 'neu': 0.657, 'pos': 0.228, 'co...</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id  label                                         tweet_text  \\\n",
       "0  1.360342e+18      1  4,000 a day dying from the so called Covid-19 ...   \n",
       "1  1.381311e+18      1  Confirmation that Chinese #vaccines \"dont hav...   \n",
       "2  1.362166e+18      3  Lab studies suggest #Pfizer, #Moderna vaccines...   \n",
       "3  1.351285e+18      1  Still want to take the #jab?\\n#PfizerBioNTech\\...   \n",
       "4  1.363344e+18      3  #Covaxin effective against mutant virus strain...   \n",
       "\n",
       "                                              scores  compound  prediction  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000           3  \n",
       "1  {'neg': 0.148, 'neu': 0.852, 'pos': 0.0, 'comp...   -0.7783           3  \n",
       "2  {'neg': 0.0, 'neu': 0.794, 'pos': 0.206, 'comp...    0.3818           1  \n",
       "3  {'neg': 0.198, 'neu': 0.759, 'pos': 0.043, 'co...   -0.6908           3  \n",
       "4  {'neg': 0.116, 'neu': 0.657, 'pos': 0.228, 'co...    0.7135           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['compound'] = tweets.scores.apply(lambda s: s['compound'])    \n",
    "tweets['prediction'] = tweets['compound'].apply(lambda c: 1 if c > 0 else 3)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y finalmente computar unas cuantas métricas de calidad del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.378448275862069\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.29      0.14       420\n",
      "           3       0.72      0.40      0.51      1900\n",
      "\n",
      "    accuracy                           0.38      2320\n",
      "   macro avg       0.41      0.34      0.33      2320\n",
      "weighted avg       0.60      0.38      0.45      2320\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 122  298]\n",
      " [1144  756]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_true = tweets.label.astype(int).to_numpy()\n",
    "y_pred = tweets.prediction.astype(int).to_numpy()\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cr = classification_report(y_true, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy:\\n{acc}\\n\")\n",
    "print(f\"Classification Report:\\n{cr}\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aún podemos hacerlo mucho mejor que la línea base (50%). Se ven problemas con las etiquetas negativas debido en parte al desbalance! Vale la pena probar con algoritmos más complejos y estrategias de balanceo. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icesi-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
